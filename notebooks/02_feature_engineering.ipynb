{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa238ee",
   "metadata": {},
   "source": [
    "# Feature engineering and Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73d790ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4b5eab",
   "metadata": {},
   "source": [
    "## Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f386ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../data/train_clean.csv')\n",
    "data_test = pd.read_csv('../data/test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe456fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1026827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1043384</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1043696</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1043852</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1044048</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sku  national_inv  lead_time  in_transit_qty  forecast_3_month  \\\n",
       "0  1026827           0.0        8.0             0.0               0.0   \n",
       "1  1043384           2.0        9.0             0.0               0.0   \n",
       "2  1043696           2.0        8.0             0.0               0.0   \n",
       "3  1043852           7.0        8.0             0.0               0.0   \n",
       "4  1044048           8.0        8.0             0.0               0.0   \n",
       "\n",
       "   forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
       "0               0.0               0.0            0.0            0.0   \n",
       "1               0.0               0.0            0.0            0.0   \n",
       "2               0.0               0.0            0.0            0.0   \n",
       "3               0.0               0.0            0.0            0.0   \n",
       "4               0.0               0.0            0.0            0.0   \n",
       "\n",
       "   sales_6_month  ...  pieces_past_due  perf_6_month_avg perf_12_month_avg  \\\n",
       "0            0.0  ...              0.0            -99.00            -99.00   \n",
       "1            0.0  ...              0.0              0.99              0.99   \n",
       "2            0.0  ...              0.0            -99.00            -99.00   \n",
       "3            0.0  ...              0.0              0.10              0.13   \n",
       "4            0.0  ...              0.0            -99.00            -99.00   \n",
       "\n",
       "   local_bo_qty  deck_risk  oe_constraint  ppap_risk stop_auto_buy rev_stop  \\\n",
       "0           0.0         No             No         No           Yes       No   \n",
       "1           0.0         No             No         No           Yes       No   \n",
       "2           0.0        Yes             No         No           Yes       No   \n",
       "3           0.0         No             No         No           Yes       No   \n",
       "4           0.0        Yes             No         No           Yes       No   \n",
       "\n",
       "  went_on_backorder  \n",
       "0                No  \n",
       "1                No  \n",
       "2                No  \n",
       "3                No  \n",
       "4                No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906fe62",
   "metadata": {},
   "source": [
    "## Handle Negative Inventory:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594cfbb6",
   "metadata": {},
   "source": [
    "Finding: In EDA, describe() output showed national_inv has a minimum value of -27256.0.\n",
    "\n",
    "Action: capping at 0 is often simpler and reasonable for inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c15f7b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_train['national_inv'] = data_train['national_inv'].clip(lower=0)\n",
    "data_test['national_inv'] = data_test['national_inv'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98257b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.687860e+06\n",
       "mean     4.964937e+02\n",
       "std      2.961518e+04\n",
       "min      0.000000e+00\n",
       "25%      4.000000e+00\n",
       "50%      1.500000e+01\n",
       "75%      8.000000e+01\n",
       "max      1.233440e+07\n",
       "Name: national_inv, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['national_inv'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940e647d",
   "metadata": {},
   "source": [
    "## Log Transformation for Skewed Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db02c6",
   "metadata": {},
   "source": [
    "Finding: EDA plots and describe() showed heavy right-skewness and large ranges for features like national_inv, in_transit_qty, forecasts (forecast_3_month, etc.), sales (sales_1_month, etc.), and min_bank. \n",
    "\n",
    "Action: Apply a log transformation (e.g., np.log1p which handles zeros by calculating log(1+x)) to these highly skewed numerical features. Apply this to both train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28f0f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_transform = ['national_inv', 'in_transit_qty',\n",
    "                     'forecast_3_month', 'forecast_6_month', \n",
    "                     'forecast_9_month', 'sales_1_month', \n",
    "                     'sales_3_month', 'sales_6_month', \n",
    "                     'sales_9_month', 'min_bank']\n",
    "\n",
    "# Apply log1p transformation to handle zeros\n",
    "# log1p(x) = log(1 + x)\n",
    "data_train[cols_to_transform] = np.log1p(data_train[cols_to_transform])\n",
    "data_test[cols_to_transform] = np.log1p(data_test[cols_to_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b383059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness Analysis (closer to 0 is better):\n",
      "\n",
      "Positive skewness indicates right-tailed distribution\n",
      "Negative skewness indicates left-tailed distribution\n",
      "\n",
      "Results:\n",
      "                  Original Skewness  Transformed Skewness  Improvement  \\\n",
      "national_inv                  0.711                -0.606        0.105   \n",
      "in_transit_qty                2.625                 1.903        0.722   \n",
      "forecast_3_month              1.837                 1.215        0.622   \n",
      "forecast_6_month              1.527                 0.930        0.597   \n",
      "forecast_9_month              1.381                 0.793        0.587   \n",
      "sales_1_month                 1.763                 0.914        0.849   \n",
      "sales_3_month                 1.293                 0.471        0.822   \n",
      "sales_6_month                 1.058                 0.236        0.822   \n",
      "sales_9_month                 0.942                 0.110        0.833   \n",
      "min_bank                      1.688                 0.901        0.787   \n",
      "\n",
      "                  Improvement %  \n",
      "national_inv             14.751  \n",
      "in_transit_qty           27.505  \n",
      "forecast_3_month         33.838  \n",
      "forecast_6_month         39.090  \n",
      "forecast_9_month         42.526  \n",
      "sales_1_month            48.148  \n",
      "sales_3_month            63.558  \n",
      "sales_6_month            77.696  \n",
      "sales_9_month            88.355  \n",
      "min_bank                 46.609  \n",
      "\n",
      "Summary:\n",
      "- 10 features showed reduced skewness after transformation\n",
      "- Average improvement: 48.2%\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate skewness stats\n",
    "def print_skewness_comparison(df, columns):\n",
    "    original_skew = df[columns].apply(lambda x: x.replace([-np.inf, np.inf], np.nan).skew())\n",
    "    \n",
    "    # Calculate log1p transformed skewness\n",
    "    transformed_data = np.log1p(df[columns])\n",
    "    transformed_skew = transformed_data.apply(lambda x: x.replace([-np.inf, np.inf], np.nan).skew())\n",
    "    \n",
    "    comparison = pd.DataFrame({\n",
    "        'Original Skewness': original_skew,\n",
    "        'Transformed Skewness': transformed_skew\n",
    "    })\n",
    "    \n",
    "    comparison['Improvement'] = comparison['Original Skewness'].abs() - comparison['Transformed Skewness'].abs()\n",
    "    comparison['Improvement %'] = (comparison['Improvement'] / comparison['Original Skewness'].abs()) * 100\n",
    "    \n",
    "    return comparison.round(3)\n",
    "\n",
    "# Calculate and display skewness comparison\n",
    "skewness_stats = print_skewness_comparison(data_train, cols_to_transform)\n",
    "print(\"Skewness Analysis (closer to 0 is better):\")\n",
    "print(\"\\nPositive skewness indicates right-tailed distribution\")\n",
    "print(\"Negative skewness indicates left-tailed distribution\")\n",
    "print(\"\\nResults:\")\n",
    "print(skewness_stats)\n",
    "\n",
    "# Additional summary\n",
    "print(\"\\nSummary:\")\n",
    "improved_features = skewness_stats[skewness_stats['Improvement'] > 0]\n",
    "print(f\"- {len(improved_features)} features showed reduced skewness after transformation\")\n",
    "print(f\"- Average improvement: {improved_features['Improvement %'].mean():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924be589",
   "metadata": {},
   "source": [
    "## Handle Coded Numerical Values (Performance Averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ba292d",
   "metadata": {},
   "source": [
    "Finding: EDA plots and conclusion highlighted that perf_6_month_avg and perf_12_month_avg have spikes at -99 and potentially 0, suggesting coded meanings (like 'no data' or 'perfect performance') rather than continuous values.\n",
    "\n",
    "Action: Treat these as categorical-like features:\n",
    "\n",
    "Binning: Create categories (e.g., 'No Data' for -99, 'Perfect' for 0, 'Below Average', 'Average', 'Above Average' for other ranges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62bd9a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in performance columns:\n",
      "\n",
      "perf_6_month_avg: [np.float64(-99.0), np.float64(0.0), np.float64(0.01), np.float64(0.02), np.float64(0.03), np.float64(0.04), np.float64(0.05), np.float64(0.06), np.float64(0.07), np.float64(0.08), np.float64(0.09), np.float64(0.1), np.float64(0.11), np.float64(0.12), np.float64(0.13), np.float64(0.14), np.float64(0.15), np.float64(0.16), np.float64(0.17), np.float64(0.18), np.float64(0.19), np.float64(0.2), np.float64(0.21), np.float64(0.22), np.float64(0.23), np.float64(0.24), np.float64(0.25), np.float64(0.26), np.float64(0.27), np.float64(0.28), np.float64(0.29), np.float64(0.3), np.float64(0.31), np.float64(0.32), np.float64(0.33), np.float64(0.34), np.float64(0.35), np.float64(0.36), np.float64(0.37), np.float64(0.38), np.float64(0.39), np.float64(0.4), np.float64(0.41), np.float64(0.42), np.float64(0.43), np.float64(0.44), np.float64(0.45), np.float64(0.46), np.float64(0.47), np.float64(0.48), np.float64(0.49), np.float64(0.5), np.float64(0.51), np.float64(0.52), np.float64(0.53), np.float64(0.54), np.float64(0.55), np.float64(0.56), np.float64(0.57), np.float64(0.58), np.float64(0.59), np.float64(0.6), np.float64(0.61), np.float64(0.62), np.float64(0.63), np.float64(0.64), np.float64(0.65), np.float64(0.66), np.float64(0.67), np.float64(0.68), np.float64(0.69), np.float64(0.7), np.float64(0.71), np.float64(0.72), np.float64(0.73), np.float64(0.74), np.float64(0.75), np.float64(0.76), np.float64(0.77), np.float64(0.78), np.float64(0.79), np.float64(0.8), np.float64(0.81), np.float64(0.82), np.float64(0.83), np.float64(0.84), np.float64(0.85), np.float64(0.86), np.float64(0.87), np.float64(0.88), np.float64(0.89), np.float64(0.9), np.float64(0.91), np.float64(0.92), np.float64(0.93), np.float64(0.94), np.float64(0.95), np.float64(0.96), np.float64(0.97), np.float64(0.98), np.float64(0.99), np.float64(1.0)]\n",
      "\n",
      "perf_12_month_avg: [np.float64(-99.0), np.float64(0.0), np.float64(0.01), np.float64(0.02), np.float64(0.03), np.float64(0.04), np.float64(0.05), np.float64(0.06), np.float64(0.07), np.float64(0.08), np.float64(0.09), np.float64(0.1), np.float64(0.11), np.float64(0.12), np.float64(0.13), np.float64(0.14), np.float64(0.15), np.float64(0.16), np.float64(0.17), np.float64(0.18), np.float64(0.19), np.float64(0.2), np.float64(0.21), np.float64(0.22), np.float64(0.23), np.float64(0.24), np.float64(0.25), np.float64(0.26), np.float64(0.27), np.float64(0.28), np.float64(0.29), np.float64(0.3), np.float64(0.31), np.float64(0.32), np.float64(0.33), np.float64(0.34), np.float64(0.35), np.float64(0.36), np.float64(0.37), np.float64(0.38), np.float64(0.39), np.float64(0.4), np.float64(0.41), np.float64(0.42), np.float64(0.43), np.float64(0.44), np.float64(0.45), np.float64(0.46), np.float64(0.47), np.float64(0.48), np.float64(0.49), np.float64(0.5), np.float64(0.51), np.float64(0.52), np.float64(0.53), np.float64(0.54), np.float64(0.55), np.float64(0.56), np.float64(0.57), np.float64(0.58), np.float64(0.59), np.float64(0.6), np.float64(0.61), np.float64(0.62), np.float64(0.63), np.float64(0.64), np.float64(0.65), np.float64(0.66), np.float64(0.67), np.float64(0.68), np.float64(0.69), np.float64(0.7), np.float64(0.71), np.float64(0.72), np.float64(0.73), np.float64(0.74), np.float64(0.75), np.float64(0.76), np.float64(0.77), np.float64(0.78), np.float64(0.79), np.float64(0.8), np.float64(0.81), np.float64(0.82), np.float64(0.83), np.float64(0.84), np.float64(0.85), np.float64(0.86), np.float64(0.87), np.float64(0.88), np.float64(0.89), np.float64(0.9), np.float64(0.91), np.float64(0.92), np.float64(0.93), np.float64(0.94), np.float64(0.95), np.float64(0.96), np.float64(0.97), np.float64(0.98), np.float64(0.99), np.float64(1.0)]\n",
      "\n",
      "Distribution of 6-month performance categories:\n",
      "perf_6_month_cat\n",
      "Below Average    1187431\n",
      "Average           278815\n",
      "No Data           129478\n",
      "Above Average      53123\n",
      "Perfect            39013\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of 12-month performance categories:\n",
      "perf_12_month_cat\n",
      "Below Average    1172307\n",
      "Average           306987\n",
      "No Data           122050\n",
      "Above Average      53541\n",
      "Perfect            32975\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of 6-month performance categories:\n",
      "perf_6_month_cat\n",
      "Below Average    1187431\n",
      "Average           278815\n",
      "No Data           129478\n",
      "Above Average      53123\n",
      "Perfect            39013\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of 12-month performance categories:\n",
      "perf_12_month_cat\n",
      "Below Average    1172307\n",
      "Average           306987\n",
      "No Data           122050\n",
      "Above Average      53541\n",
      "Perfect            32975\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# First, let's examine the unique values in performance columns\n",
    "print(\"Unique values in performance columns:\")\n",
    "print(\"\\nperf_6_month_avg:\", sorted(data_train['perf_6_month_avg'].unique()))\n",
    "print(\"\\nperf_12_month_avg:\", sorted(data_train['perf_12_month_avg'].unique()))\n",
    "\n",
    "# Function to categorize performance\n",
    "def categorize_performance(value):\n",
    "    if value == -99:\n",
    "        return 'No Data'\n",
    "    elif value == 0:\n",
    "        return 'Perfect'\n",
    "    elif value < 0.3:  #this  can adjust these thresholds based on domain knowledge\n",
    "        return 'Above Average'\n",
    "    elif value < 0.7:\n",
    "        return 'Average'\n",
    "    else:\n",
    "        return 'Below Average'\n",
    "\n",
    "# Create new categorical columns\n",
    "data_train['perf_6_month_cat'] = data_train['perf_6_month_avg'].apply(categorize_performance)\n",
    "data_train['perf_12_month_cat'] = data_train['perf_12_month_avg'].apply(categorize_performance)\n",
    "data_test['perf_6_month_cat'] = data_test['perf_6_month_avg'].apply(categorize_performance)\n",
    "data_test['perf_12_month_cat'] = data_test['perf_12_month_avg'].apply(categorize_performance)\n",
    "\n",
    "# Look at the distribution of categories\n",
    "print(\"\\nDistribution of 6-month performance categories:\")\n",
    "print(data_train['perf_6_month_cat'].value_counts())\n",
    "print(\"\\nDistribution of 12-month performance categories:\")\n",
    "print(data_train['perf_12_month_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439ddf99",
   "metadata": {},
   "source": [
    "## Encode Categorical Features\n",
    "\n",
    "Finding: While EDA focused on numerical, dataset description mentions several Yes/No columns (potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_buy, rev_stop) which act as binary categories.\n",
    "\n",
    "Action: Convert these Yes/No columns into numerical representations (0 and 1). (pd.get_dummies with drop_first=True or simple mapping like {'Yes': 1, 'No': 0})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fa05d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sku', 'national_inv', 'lead_time', 'in_transit_qty',\n",
       "       'forecast_3_month', 'forecast_6_month', 'forecast_9_month',\n",
       "       'sales_1_month', 'sales_3_month', 'sales_6_month', 'sales_9_month',\n",
       "       'min_bank', 'potential_issue', 'pieces_past_due', 'perf_6_month_avg',\n",
       "       'perf_12_month_avg', 'local_bo_qty', 'deck_risk', 'oe_constraint',\n",
       "       'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder',\n",
       "       'perf_6_month_cat', 'perf_12_month_cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f1305d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in other potential categorical columns:\n",
      "\n",
      "potential_issue: ['No', 'Yes']\n",
      "\n",
      "deck_risk: ['No', 'Yes']\n",
      "\n",
      "oe_constraint: ['No', 'Yes']\n",
      "\n",
      "ppap_risk: ['No', 'Yes']\n",
      "\n",
      "stop_auto_buy: ['No', 'Yes']\n",
      "\n",
      "oe_constraint: ['No', 'Yes']\n",
      "\n",
      "ppap_risk: ['No', 'Yes']\n",
      "\n",
      "stop_auto_buy: ['No', 'Yes']\n",
      "\n",
      "rev_stop: ['No', 'Yes']\n",
      "\n",
      "went_on_backorder: ['No', 'Yes']\n",
      "\n",
      "rev_stop: ['No', 'Yes']\n",
      "\n",
      "went_on_backorder: ['No', 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# Let's also look at other potential categorical columns\n",
    "binary_cols = ['potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk', \n",
    "               'stop_auto_buy', 'rev_stop', 'went_on_backorder']\n",
    "\n",
    "print(\"\\nUnique values in other potential categorical columns:\")\n",
    "for col in binary_cols:\n",
    "    print(f\"\\n{col}:\", sorted(data_train[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "442d3f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary columns after encoding (sample):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>potential_issue</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   potential_issue  deck_risk  oe_constraint  ppap_risk  stop_auto_buy  \\\n",
       "0                0          0              0          0              1   \n",
       "1                0          0              0          0              1   \n",
       "2                0          1              0          0              1   \n",
       "3                0          0              0          0              1   \n",
       "4                0          1              0          0              1   \n",
       "\n",
       "   rev_stop  went_on_backorder  \n",
       "0         0                  0  \n",
       "1         0                  0  \n",
       "2         0                  0  \n",
       "3         0                  0  \n",
       "4         0                  0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the original performance columns since we now have categorical versions\n",
    "columns_to_drop = ['perf_6_month_avg', 'perf_12_month_avg']\n",
    "data_train.drop(columns=columns_to_drop, inplace=True)\n",
    "data_test.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Convert all binary columns to numeric (0/1) for machine learning\n",
    "binary_cols = ['potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk', \n",
    "               'stop_auto_buy', 'rev_stop', 'went_on_backorder']\n",
    "\n",
    "for col in binary_cols:\n",
    "    data_train[col] = (data_train[col] == 'Yes').astype(int)\n",
    "    data_test[col] = (data_test[col] == 'Yes').astype(int)\n",
    "\n",
    "# Create dummy variables for the performance categories\n",
    "# This will one-hot encode our new categorical columns\n",
    "perf_columns = ['perf_6_month_cat', 'perf_12_month_cat']\n",
    "data_train = pd.get_dummies(data_train, columns=perf_columns, prefix=perf_columns)\n",
    "data_test = pd.get_dummies(data_test, columns=perf_columns, prefix=perf_columns)\n",
    "\n",
    "# Verify the transformations\n",
    "print(\"Binary columns after encoding (sample):\")\n",
    "data_train[binary_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de9d214a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance categories after one-hot encoding (sample):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perf_6_month_cat_Above Average</th>\n",
       "      <th>perf_6_month_cat_Average</th>\n",
       "      <th>perf_6_month_cat_Below Average</th>\n",
       "      <th>perf_6_month_cat_No Data</th>\n",
       "      <th>perf_6_month_cat_Perfect</th>\n",
       "      <th>perf_12_month_cat_Above Average</th>\n",
       "      <th>perf_12_month_cat_Average</th>\n",
       "      <th>perf_12_month_cat_Below Average</th>\n",
       "      <th>perf_12_month_cat_No Data</th>\n",
       "      <th>perf_12_month_cat_Perfect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   perf_6_month_cat_Above Average  perf_6_month_cat_Average  \\\n",
       "0                           False                     False   \n",
       "1                           False                     False   \n",
       "2                           False                     False   \n",
       "3                            True                     False   \n",
       "4                           False                     False   \n",
       "\n",
       "   perf_6_month_cat_Below Average  perf_6_month_cat_No Data  \\\n",
       "0                           False                      True   \n",
       "1                            True                     False   \n",
       "2                           False                      True   \n",
       "3                           False                     False   \n",
       "4                           False                      True   \n",
       "\n",
       "   perf_6_month_cat_Perfect  perf_12_month_cat_Above Average  \\\n",
       "0                     False                            False   \n",
       "1                     False                            False   \n",
       "2                     False                            False   \n",
       "3                     False                             True   \n",
       "4                     False                            False   \n",
       "\n",
       "   perf_12_month_cat_Average  perf_12_month_cat_Below Average  \\\n",
       "0                      False                            False   \n",
       "1                      False                             True   \n",
       "2                      False                            False   \n",
       "3                      False                            False   \n",
       "4                      False                            False   \n",
       "\n",
       "   perf_12_month_cat_No Data  perf_12_month_cat_Perfect  \n",
       "0                       True                      False  \n",
       "1                      False                      False  \n",
       "2                       True                      False  \n",
       "3                      False                      False  \n",
       "4                       True                      False  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nPerformance categories after one-hot encoding (sample):\")\n",
    "perf_dummy_cols = [col for col in data_train.columns if col.startswith('perf_')]\n",
    "data_train[perf_dummy_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8721dca3",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "Finding: Numerical features operate on vastly different scales (e.g., inventory vs. lead time). \n",
    "\n",
    "Action: Apply scaling to numerical features (after transformations like log).\n",
    "\n",
    "we use StandardScaler because:\n",
    "- data is already log-transformed\n",
    "- features centered around 0 with unit variance\n",
    "- works well with most ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c39496d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features after scaling (train data):\n",
      "       national_inv   lead_time  in_transit_qty  forecast_3_month  \\\n",
      "count    1687860.00  1687860.00      1687860.00        1687860.00   \n",
      "mean          -0.00       -0.00           -0.00              0.00   \n",
      "std            1.00        1.00            1.00              1.00   \n",
      "min           -1.56       -1.15           -0.42             -0.55   \n",
      "25%           -0.76       -0.57           -0.42             -0.55   \n",
      "50%           -0.18        0.02           -0.42             -0.55   \n",
      "75%            0.63        0.02           -0.42              0.25   \n",
      "max            6.59        6.45            8.49              6.50   \n",
      "\n",
      "       forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
      "count        1687860.00        1687860.00     1687860.00     1687860.00   \n",
      "mean               0.00             -0.00           0.00           0.00   \n",
      "std                1.00              1.00           1.00           1.00   \n",
      "min               -0.62             -0.66          -0.65          -0.79   \n",
      "25%               -0.62             -0.66          -0.65          -0.79   \n",
      "50%               -0.62             -0.66          -0.65          -0.45   \n",
      "75%                0.50              0.59           0.34           0.57   \n",
      "max                5.83              5.55           7.61           6.03   \n",
      "\n",
      "       sales_6_month  sales_9_month    min_bank  pieces_past_due  local_bo_qty  \n",
      "count     1687860.00     1687860.00  1687860.00       1687860.00    1687860.00  \n",
      "mean           -0.00          -0.00        0.00            -0.00          0.00  \n",
      "std             1.00           1.00        1.00             1.00          1.00  \n",
      "min            -0.88          -0.94       -0.66            -0.01         -0.02  \n",
      "25%            -0.88          -0.94       -0.66            -0.01         -0.02  \n",
      "50%            -0.40          -0.27       -0.66            -0.01         -0.02  \n",
      "75%             0.64           0.67        0.16            -0.01         -0.02  \n",
      "max             5.53           5.28        6.86           620.69        371.55  \n",
      "       national_inv   lead_time  in_transit_qty  forecast_3_month  \\\n",
      "count    1687860.00  1687860.00      1687860.00        1687860.00   \n",
      "mean          -0.00       -0.00           -0.00              0.00   \n",
      "std            1.00        1.00            1.00              1.00   \n",
      "min           -1.56       -1.15           -0.42             -0.55   \n",
      "25%           -0.76       -0.57           -0.42             -0.55   \n",
      "50%           -0.18        0.02           -0.42             -0.55   \n",
      "75%            0.63        0.02           -0.42              0.25   \n",
      "max            6.59        6.45            8.49              6.50   \n",
      "\n",
      "       forecast_6_month  forecast_9_month  sales_1_month  sales_3_month  \\\n",
      "count        1687860.00        1687860.00     1687860.00     1687860.00   \n",
      "mean               0.00             -0.00           0.00           0.00   \n",
      "std                1.00              1.00           1.00           1.00   \n",
      "min               -0.62             -0.66          -0.65          -0.79   \n",
      "25%               -0.62             -0.66          -0.65          -0.79   \n",
      "50%               -0.62             -0.66          -0.65          -0.45   \n",
      "75%                0.50              0.59           0.34           0.57   \n",
      "max                5.83              5.55           7.61           6.03   \n",
      "\n",
      "       sales_6_month  sales_9_month    min_bank  pieces_past_due  local_bo_qty  \n",
      "count     1687860.00     1687860.00  1687860.00       1687860.00    1687860.00  \n",
      "mean           -0.00          -0.00        0.00            -0.00          0.00  \n",
      "std             1.00           1.00        1.00             1.00          1.00  \n",
      "min            -0.88          -0.94       -0.66            -0.01         -0.02  \n",
      "25%            -0.88          -0.94       -0.66            -0.01         -0.02  \n",
      "50%            -0.40          -0.27       -0.66            -0.01         -0.02  \n",
      "75%             0.64           0.67        0.16            -0.01         -0.02  \n",
      "max             5.53           5.28        6.86           620.69        371.55  \n",
      "\n",
      "Verification - features should have mean ≈ 0 and std ≈ 1:\n",
      "\n",
      "Means:\n",
      "national_inv       -0.0\n",
      "lead_time          -0.0\n",
      "in_transit_qty     -0.0\n",
      "forecast_3_month    0.0\n",
      "forecast_6_month    0.0\n",
      "forecast_9_month   -0.0\n",
      "sales_1_month       0.0\n",
      "sales_3_month       0.0\n",
      "sales_6_month      -0.0\n",
      "sales_9_month      -0.0\n",
      "min_bank            0.0\n",
      "pieces_past_due    -0.0\n",
      "local_bo_qty        0.0\n",
      "dtype: float64\n",
      "\n",
      "Standard deviations:\n",
      "national_inv        1.0\n",
      "lead_time           1.0\n",
      "in_transit_qty      1.0\n",
      "forecast_3_month    1.0\n",
      "forecast_6_month    1.0\n",
      "forecast_9_month    1.0\n",
      "sales_1_month       1.0\n",
      "sales_3_month       1.0\n",
      "sales_6_month       1.0\n",
      "sales_9_month       1.0\n",
      "min_bank            1.0\n",
      "pieces_past_due     1.0\n",
      "local_bo_qty        1.0\n",
      "dtype: float64\n",
      "\n",
      "Verification - features should have mean ≈ 0 and std ≈ 1:\n",
      "\n",
      "Means:\n",
      "national_inv       -0.0\n",
      "lead_time          -0.0\n",
      "in_transit_qty     -0.0\n",
      "forecast_3_month    0.0\n",
      "forecast_6_month    0.0\n",
      "forecast_9_month   -0.0\n",
      "sales_1_month       0.0\n",
      "sales_3_month       0.0\n",
      "sales_6_month      -0.0\n",
      "sales_9_month      -0.0\n",
      "min_bank            0.0\n",
      "pieces_past_due    -0.0\n",
      "local_bo_qty        0.0\n",
      "dtype: float64\n",
      "\n",
      "Standard deviations:\n",
      "national_inv        1.0\n",
      "lead_time           1.0\n",
      "in_transit_qty      1.0\n",
      "forecast_3_month    1.0\n",
      "forecast_6_month    1.0\n",
      "forecast_9_month    1.0\n",
      "sales_1_month       1.0\n",
      "sales_3_month       1.0\n",
      "sales_6_month       1.0\n",
      "sales_9_month       1.0\n",
      "min_bank            1.0\n",
      "pieces_past_due     1.0\n",
      "local_bo_qty        1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify numerical columns to scale (excluding binary and one-hot encoded columns)\n",
    "numerical_cols = ['national_inv', 'lead_time', 'in_transit_qty',\n",
    "                  'forecast_3_month', 'forecast_6_month', 'forecast_9_month',\n",
    "                  'sales_1_month', 'sales_3_month', 'sales_6_month', \n",
    "                  'sales_9_month', 'min_bank', 'pieces_past_due',\n",
    "                  'local_bo_qty']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on training data only\n",
    "scaler.fit(data_train[numerical_cols])\n",
    "\n",
    "# Transform both training and test data\n",
    "data_train[numerical_cols] = scaler.transform(data_train[numerical_cols])\n",
    "data_test[numerical_cols] = scaler.transform(data_test[numerical_cols])\n",
    "\n",
    "# Verify the scaling worked as expected\n",
    "print(\"Numerical features after scaling (train data):\")\n",
    "print(data_train[numerical_cols].describe().round(2))\n",
    "\n",
    "# Verify that the scaled features have mean ≈ 0 and std ≈ 1\n",
    "means = data_train[numerical_cols].mean()\n",
    "stds = data_train[numerical_cols].std()\n",
    "\n",
    "print(\"\\nVerification - features should have mean ≈ 0 and std ≈ 1:\")\n",
    "print(\"\\nMeans:\")\n",
    "print(means.round(4))\n",
    "print(\"\\nStandard deviations:\")\n",
    "print(stds.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d9c6c1",
   "metadata": {},
   "source": [
    "## Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "716254a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final features: ['sku', 'national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month', 'forecast_6_month', 'forecast_9_month', 'sales_1_month', 'sales_3_month', 'sales_6_month', 'sales_9_month', 'min_bank', 'potential_issue', 'pieces_past_due', 'local_bo_qty', 'deck_risk', 'oe_constraint', 'ppap_risk', 'stop_auto_buy', 'rev_stop', 'went_on_backorder', 'perf_6_month_cat_Above Average', 'perf_6_month_cat_Average', 'perf_6_month_cat_Below Average', 'perf_6_month_cat_No Data', 'perf_6_month_cat_Perfect', 'perf_12_month_cat_Above Average', 'perf_12_month_cat_Average', 'perf_12_month_cat_Below Average', 'perf_12_month_cat_No Data', 'perf_12_month_cat_Perfect']\n",
      "\n",
      "Total number of features: 31\n"
     ]
    }
   ],
   "source": [
    "# First, let's see what features we have\n",
    "print(\"Final features:\", data_train.columns.tolist())\n",
    "print(\"\\nTotal number of features:\", len(data_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9872ce8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datasets saved successfully!\n",
      "Train shape: (1687860, 31)\n",
      "Test shape: (242075, 31)\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "data_train.to_csv('../data/train_processed.csv', index=False)\n",
    "data_test.to_csv('../data/test_processed.csv', index=False)\n",
    "\n",
    "print(\"\\nDatasets saved successfully!\")\n",
    "print(f\"Train shape: {data_train.shape}\")\n",
    "print(f\"Test shape: {data_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94671ad",
   "metadata": {},
   "source": [
    "## Summary of Feature Engineering\n",
    "\n",
    "1. **Handled Missing & Invalid Data**\n",
    "   - Dropped incomplete rows in 'went_on_backorder'\n",
    "   - Filled missing lead_time with median\n",
    "   - Clipped negative inventory values to 0\n",
    "\n",
    "2. **Log Transformation**\n",
    "   - Applied to highly skewed numerical features\n",
    "   - Used np.log1p to handle zeros\n",
    "   - Significantly reduced skewness\n",
    "\n",
    "3. **Categorical Encoding**\n",
    "   - Converted binary Yes/No columns to 0/1\n",
    "   - Created categorical versions of performance metrics\n",
    "   - Applied one-hot encoding to performance categories\n",
    "\n",
    "4. **Feature Scaling**\n",
    "   - Applied StandardScaler to numerical features\n",
    "   - Fit on training data only\n",
    "   - Applied same transformation to test data\n",
    "\n",
    "Next Steps (for modeling notebook):\n",
    "- Feature selection\n",
    "- Feature importance analysis\n",
    "- Model-specific feature engineering if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
